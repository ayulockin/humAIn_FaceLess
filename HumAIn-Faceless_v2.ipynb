{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nimport cv2\nimport random\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nimport keras.backend as K\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers import Dense, Flatten, BatchNormalization, Dropout\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import to_categorical\nfrom keras.optimizers import Adam\nfrom keras.applications import VGG16\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Paths and Files"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"imagesPath = '/kaggle/input/utkface-images/utkfaceimages/UTKFaceImages/'\nlabelsPath = '/kaggle/input/utkface-images/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files = os.listdir(labelsPath)\nlabels = pd.read_csv(labelsPath+files[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Clean data"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = labels[labels.ethnicity != '20170109150557335.jpg.chip.jpg']\nlabels = labels[labels.ethnicity != '20170116174525125.jpg.chip.jpg']\nlabels = labels[labels.ethnicity != '20170109142408075.jpg.chip.jpg']\n\nlabels = labels.astype({'ethnicity': 'int64'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images = os.listdir(imagesPath)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train-Validation-Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"def groupAge(age):\n#     [0, 5, 18, 24, 26, 27, 30, 34, 38, 46, 55, 65, len(ages)])\n    if age>=0 and age<5:\n        return 0\n    elif age>=5 and age<18:\n        return 1\n    elif age>=18 and age<24:\n        return 2\n    elif age>=24 and age<26:\n        return 3\n    elif age>=26 and age<27:\n        return 4\n    elif age>=27 and age<30:\n        return 5\n    elif age>=30 and age<34:\n        return 6\n    elif age>=34 and age<38:\n        return 7\n    elif age>=38 and age<46:\n        return 8\n    elif age>=46 and age<55:\n        return 9\n    elif age>=55 and age<65:\n        return 10\n    else:\n        return 11","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train:validation:test = 60:10:30 = 14225:948:8535\npartitions = {'train': [],\n             'validation': [],\n             'test': []}\nlabels_dict = {'train_age': [], 'train_gender': [], 'train_ethnicity': [],\n          'validation_age': [], 'validation_gender': [], 'validation_ethnicity': [],\n         'test_age': [], 'test_gender': [], 'test_ethnicity': []}\n\ndiscared_data = []\n\nrandom.seed(1)\nrandom.shuffle(images)\n\nprint(\"[INFO] Preparing train data....\")\nfor ID in range(14225):\n    try:\n        data = labels.loc[labels['image_id'] == images[ID][:-4]].values\n        labels_dict['train_age'].append(to_categorical(groupAge(data[0][1]), num_classes=12, dtype='float32'))\n        labels_dict['train_gender'].append(data[0][2])\n        labels_dict['train_ethnicity'].append(to_categorical(data[0][3], num_classes=5, dtype='float32'))\n        partitions['train'].append(images[ID])\n    except IndexError:\n        print(\"[ERROR]\", images[ID])\n        discared_data.append(images[ID])\nprint(\"[INFO] Done\")\n\nprint(\"[INFO] Preparing validation data....\")\nfor ID in range(14225, 15173):\n    try:\n        data = labels.loc[labels['image_id'] == images[ID][:-4]].values\n        labels_dict['validation_age'].append(to_categorical(groupAge(data[0][1]), num_classes=12, dtype='float32'))\n        labels_dict['validation_gender'].append(data[0][2])\n        labels_dict['validation_ethnicity'].append(to_categorical(data[0][3], num_classes=5, dtype='float32'))\n        partitions['validation'].append(images[ID])\n    except IndexError:\n        print(\"[ERROR]\", images[ID])\n        discared_data.append(images[ID])\nprint(\"[INFO] Done\")\n\nprint(\"[INFO] Preparing test data....\")\nfor ID in range(15173, len(images)):\n    try:\n        data = labels.loc[labels['image_id'] == images[ID][:-4]].values\n        labels_dict['test_age'].append(to_categorical(groupAge(data[0][1]), num_classes=12, dtype='float32'))\n        labels_dict['test_gender'].append(data[0][2])\n        labels_dict['test_ethnicity'].append(to_categorical(data[0][3], num_classes=5, dtype='float32'))\n        partitions['test'].append(images[ID])\n    except IndexError:\n        print(\"[ERROR]\", images[ID])\n        discared_data.append(images[ID])\nprint(\"[INFO] Done\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> [ERROR] is due to data cleaning process. There were three data points with wrong ethnicity. "},{"metadata":{},"cell_type":"markdown","source":"#### EDA on the split"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"[INFO] Training Data\")\nprint(\"Size of train data: \", len(partitions['train']))\nprint(\"Size of age as label: \", len(labels_dict['train_age']))\nprint(\"Size of gender as label: \", len(labels_dict['train_gender']))\nprint(\"Size of ethnicity as label: \", len(labels_dict['train_ethnicity']))\nprint(\"\\n\")\nprint(\"[INFO] Validation Data\")\nprint(\"Size of validation data: \", len(partitions['validation']))\nprint(\"Size of age as label: \", len(labels_dict['validation_age']))\nprint(\"Size of gender as label: \", len(labels_dict['validation_gender']))\nprint(\"Size of ethnicity as label: \", len(labels_dict['validation_ethnicity']))\nprint(\"\\n\")\nprint(\"[INFO] Test Data\")\nprint(\"Size of test data: \", len(partitions['test']))\nprint(\"Size of age as label: \", len(labels_dict['test_age']))\nprint(\"Size of gender as label: \", len(labels_dict['test_gender']))\nprint(\"Size of ethnicity as label: \", len(labels_dict['test_ethnicity']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def buildModel():\n    inputs = Input(shape=(200,200,3))\n    vgg16 = VGG16(weights='imagenet', include_top=False)(inputs)\n    x = Flatten()(vgg16)\n    x = BatchNormalization()(x)\n    x = Dense(1024, activation='relu')(x)\n    x = Dense(512, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dense(128, activation='relu')(x)\n    x = Dense(64, activation='relu')(x)\n    x_gender = Dense(1, activation='sigmoid', name='gender')(x)\n    x_ethnicity = Dense(5, activation='softmax', name='ethnicity')(x)\n    x_age = Dense(12, activation='softmax', name='age')(x)\n\n    model = Model(inputs=inputs, outputs=[x_gender, x_ethnicity, x_age])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = buildModel()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prepare Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"def loadImages(images, imagesPath, discared_data):\n    print(\"[INFO] Loading....\")\n    X = []\n    count = 0\n    for image in images:\n        if image in discared_data:\n            continue\n        if count%1000==0:\n            print(\"[INFO] {} images loaded\".format(count))\n        img = cv2.imread(imagesPath+image)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        X.append(img)\n        count+=1\n    print(\"[INFO] Done\")\n    return np.array(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"[INFO] Training Data\")\ntrainX = loadImages(partitions['train'], imagesPath, discared_data)\nprint(\"[INFO] Validation Data\")\nvalidationX = loadImages(partitions['validation'], imagesPath, discared_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"[INFO] no. of Training Images: \", len(trainX))\nprint(\"[INFO] no. of Validation Images: \", len(validationX))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainY = {\n    'gender': np.array(labels_dict['train_gender']),\n    'ethnicity': np.array(labels_dict['train_ethnicity']),\n    'age': np.array(labels_dict['train_age'])\n}\n\nvalidationY = {\n    'gender': np.array(labels_dict['validation_gender']),\n    'ethnicity': np.array(labels_dict['validation_ethnicity']),\n    'age': np.array(labels_dict['validation_age'])\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainY['gender'] = trainY['gender'].reshape(trainY['gender'].shape[0], 1)\nvalidationY['gender'] = validationY['gender'].reshape(validationY['gender'].shape[0], 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hyperparameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 50\nlr = 1e-3\nbatch_size = 32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"losses = {\n    'gender': 'binary_crossentropy',\n    'ethnicity': 'categorical_crossentropy',\n    'age': 'categorical_crossentropy'\n}\n\nlosses_weights = {\n    'gender': 1.0,\n    'ethnicity': 1.0,\n    'age': 1.0\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt = Adam(lr=lr, decay=lr / epochs)\nmodel.compile(optimizer=opt, loss=losses, loss_weights=losses_weights, metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MultiOutputDataGenerator(ImageDataGenerator):\n    def flow(self,\n             x,\n             y=None,\n             batch_size=32,\n             shuffle=True,\n             sample_weight=None,\n             seed=None,\n             save_to_dir=None,\n             save_prefix='',\n             save_format='png',\n             subset=None):\n\n        targets = None\n        target_lengths = {}\n        ordered_outputs = []\n        for output, target in y.items():\n            if targets is None:\n                targets = target\n            else:\n                targets = np.concatenate((targets, target), axis=1)\n            target_lengths[output] = target.shape[1]\n            ordered_outputs.append(output)\n            \n        for flowx, flowy in super().flow(x, targets, batch_size=batch_size,\n                                         shuffle=shuffle):\n            target_dict = {}\n            i = 0\n            for output in ordered_outputs:\n                target_length = target_lengths[output]\n                target_dict[output] = flowy[:, i: i + target_length]\n                i += target_length\n\n            yield flowx, target_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"multiclassgenerator = MultiOutputDataGenerator(ImageDataGenerator(rescale=1.0/255.0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traingenerator = multiclassgenerator.flow(trainX, trainY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validationgenerator = multiclassgenerator.flow(validationX, validationY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"earlyStopper = EarlyStopping(monitor='loss', patience=5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Train"},{"metadata":{"trusted":true},"cell_type":"code","source":"hist = model.fit_generator(traingenerator, validation_data=validationgenerator, epochs=epochs, \n                           steps_per_epoch=len(trainX)//batch_size, validation_steps=len(validationX)//batch_size, \n                           callbacks=[earlyStopper])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loss-Accuracy Plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"lossNames = ['loss', 'gender_loss', 'ethnicity_loss', \n             'age_loss']\n\nplt.style.use(\"seaborn-whitegrid\")\n(fig, ax) = plt.subplots(4, 1, figsize=(13, 13))\n \n# loop over the loss names\nfor (i, l) in enumerate(lossNames):\n    title = \"Loss for {}\".format(l) if l != \"loss\" else \"Total loss\"\n    ax[i].set_title(title)\n    ax[i].set_xlabel(\"Epoch #\")\n    ax[i].set_ylabel(\"Loss\")\n    ax[i].set_xlim([0, epochs])\n#     ax[i].set_ylim([0,max(max(hist.history[l]), max(hist.history[\"val_\" + l]))])\n    ax[i].plot(hist.history[l], label=l)\n    ax[i].plot(hist.history[\"val_\" + l],\n\t\tlabel=\"val_\" + l)\n    ax[i].legend()\n \n# save the losses figure and create a new figure for the accuracies\nplt.tight_layout()\n# plt.savefig(\"{}_losses.png\".format(args[\"plot\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lossNames = ['gender_acc', 'ethnicity_acc', \n             'age_acc']\n\nplt.style.use(\"seaborn-whitegrid\")\n(fig, ax) = plt.subplots(3, 1, figsize=(13, 13))\n \n# loop over the loss names\nfor (i, l) in enumerate(lossNames):\n    ax[i].set_title(\"Accuracy for {}\".format(l))\n    ax[i].set_xlabel(\"Epoch #\")\n    ax[i].set_ylabel(\"Accuracy\")\n    ax[i].set_xlim([0, epochs])\n#     ax[i].set_ylim([0,max(max(hist.history[l]), max(hist.history[\"val_\" + l]))])\n    ax[i].plot(hist.history[l], label=l)\n    ax[i].plot(hist.history[\"val_\" + l],\n\t\tlabel=\"val_\" + l)\n    ax[i].legend()\n \n# save the losses figure and create a new figure for the accuracies\nplt.tight_layout()\n# plt.savefig(\"Accuracy_epochs{}.png\".format(epochs))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('age-gender-race_v2.h5')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}